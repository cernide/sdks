syntax = "proto3";

package v1;

import "v1/polyflow/environment.proto";
import "v1/polyflow/init.proto";
import "v1/polyflow/k8s.proto";

option go_package = "v1/polyflow";

// Spark replica definition
message SparkReplica {
    // Number of replicas
    int32 replicas = 1;

    // Optional environment section
    Environment environment = 2;

    // Optional init connections section
    repeated Init init = 3;

    // Optional sidecars section
    repeated Container sidecars = 4;

    // Optional container to run
    Container container = 5;
}

// Spark specification
message Spark {
    // Kind of runtime, should be equal to "spark"
    string kind = 1;

    // Optional connections section
    repeated string connections = 2;

    // Volumes is a list of volumes that can be mounted.
    repeated Volume volumes = 3;

    enum Type {
        java = 0;
        scala = 1;
        python = 2;
        r = 3;
    }

    // Type tells the type of the Spark application.
    Type type = 4;

    // Spark version is the version of Spark the application uses.
    string sparkVersion = 5;

    // Spark version is the version of Spark the application uses.
    string pythonVersion = 6;


    enum DeployMode {
        cluster = 0;
        client = 1;
        in_cluster_client = 2;
    }
    // Mode is the deployment mode of the Spark application.
    DeployMode deployMode = 7;

    // MainClass is the fully-qualified main class of the Spark application.
    // This only applies to Java/Scala Spark applications.
    string mainClass = 8;

    // MainFile is the path to a bundled JAR, Python, or R file of the application.
    string mainApplicationFile = 9;

    // Arguments is a list of arguments to be passed to the application.
    repeated string arguments = 10;

    // HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
    // in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
    // configuration properties.
    map<string, string> hadoopConf = 11;

    // HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
	  // in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
	  // configuration properties.
    map<string, string> sparkConf = 12;

    // SparkConfigMap carries the name of the ConfigMap containing Spark configuration files such as log4j.properties.
	  // The controller will add environment variable SPARK_CONF_DIR to the path where the ConfigMap is mounted to.
    string sparkConfigMap = 13;

	  // HadoopConfigMap carries the name of the ConfigMap containing Hadoop configuration files such as core-site.xml.
	  // The controller will add environment variable HADOOP_CONF_DIR to the path where the ConfigMap is mounted to.
	  string hadoopConfigMap = 14;

    // Optional spark executor definition
    SparkReplica executor = 15;

    // Optional spark driver definition
    SparkReplica driver = 16;
}

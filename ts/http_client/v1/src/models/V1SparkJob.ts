/* tslint:disable */
/* eslint-disable */
/**
 * Polyaxon SDKs and REST API specification.
 *
 *
 * The version of the OpenAPI document: 2.0.0-rc28
 * Contact: contact@polyaxon.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { exists, mapValues } from '../runtime';
import type { SparkJobDeployMode } from './SparkJobDeployMode';
import {
    SparkJobDeployModeFromJSON,
    SparkJobDeployModeFromJSONTyped,
    SparkJobDeployModeToJSON,
} from './SparkJobDeployMode';
import type { V1SparkJobType } from './V1SparkJobType';
import {
    V1SparkJobTypeFromJSON,
    V1SparkJobTypeFromJSONTyped,
    V1SparkJobTypeToJSON,
} from './V1SparkJobType';
import type { V1SparkReplica } from './V1SparkReplica';
import {
    V1SparkReplicaFromJSON,
    V1SparkReplicaFromJSONTyped,
    V1SparkReplicaToJSON,
} from './V1SparkReplica';

/**
 *
 * @export
 * @interface V1SparkJob
 */
export interface V1SparkJob {
    /**
     *
     * @type {string}
     * @memberof V1SparkJob
     */
    kind?: string;
    /**
     *
     * @type {Array<string>}
     * @memberof V1SparkJob
     */
    connections?: Array<string>;
    /**
     * Volumes is a list of volumes that can be mounted.
     * @type {Array<object>}
     * @memberof V1SparkJob
     */
    volumes?: Array<object>;
    /**
     *
     * @type {V1SparkJobType}
     * @memberof V1SparkJob
     */
    type?: V1SparkJobType;
    /**
     * Spark version is the version of Spark the application uses.
     * @type {string}
     * @memberof V1SparkJob
     */
    sparkVersion?: string;
    /**
     * Spark version is the version of Spark the application uses.
     * @type {string}
     * @memberof V1SparkJob
     */
    pythonVersion?: string;
    /**
     *
     * @type {SparkJobDeployMode}
     * @memberof V1SparkJob
     */
    deployMode?: SparkJobDeployMode;
    /**
     * MainClass is the fully-qualified main class of the Spark application.
     * This only applies to Java/Scala Spark applications.
     * @type {string}
     * @memberof V1SparkJob
     */
    mainClass?: string;
    /**
     * MainFile is the path to a bundled JAR, Python, or R file of the application.
     * @type {string}
     * @memberof V1SparkJob
     */
    mainApplicationFile?: string;
    /**
     * Arguments is a list of arguments to be passed to the application.
     * @type {Array<string>}
     * @memberof V1SparkJob
     */
    arguments?: Array<string>;
    /**
     * HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
     * in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
     * configuration properties.
     * @type {{ [key: string]: string; }}
     * @memberof V1SparkJob
     */
    hadoopConf?: { [key: string]: string; };
    /**
     * HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
     * in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
     * configuration properties.
     * @type {{ [key: string]: string; }}
     * @memberof V1SparkJob
     */
    sparkConf?: { [key: string]: string; };
    /**
     * SparkConfigMap carries the name of the ConfigMap containing Spark configuration files such as log4j.properties.
     * The controller will add environment variable SPARK_CONF_DIR to the path where the ConfigMap is mounted to.
     * @type {string}
     * @memberof V1SparkJob
     */
    sparkConfigMap?: string;
    /**
     * HadoopConfigMap carries the name of the ConfigMap containing Hadoop configuration files such as core-site.xml.
     * The controller will add environment variable HADOOP_CONF_DIR to the path where the ConfigMap is mounted to.
     * @type {string}
     * @memberof V1SparkJob
     */
    hadoopConfigMap?: string;
    /**
     *
     * @type {V1SparkReplica}
     * @memberof V1SparkJob
     */
    executor?: V1SparkReplica;
    /**
     *
     * @type {V1SparkReplica}
     * @memberof V1SparkJob
     */
    driver?: V1SparkReplica;
}

/**
 * Check if a given object implements the V1SparkJob interface.
 */
export function instanceOfV1SparkJob(value: object): boolean {
    let isInstance = true;

    return isInstance;
}

export function V1SparkJobFromJSON(json: any): V1SparkJob {
    return V1SparkJobFromJSONTyped(json, false);
}

export function V1SparkJobFromJSONTyped(json: any, ignoreDiscriminator: boolean): V1SparkJob {
    if ((json === undefined) || (json === null)) {
        return json;
    }
    return {

        'kind': !exists(json, 'kind') ? undefined : json['kind'],
        'connections': !exists(json, 'connections') ? undefined : json['connections'],
        'volumes': !exists(json, 'volumes') ? undefined : json['volumes'],
        'type': !exists(json, 'type') ? undefined : V1SparkJobTypeFromJSON(json['type']),
        'sparkVersion': !exists(json, 'sparkVersion') ? undefined : json['sparkVersion'],
        'pythonVersion': !exists(json, 'pythonVersion') ? undefined : json['pythonVersion'],
        'deployMode': !exists(json, 'deployMode') ? undefined : SparkJobDeployModeFromJSON(json['deployMode']),
        'mainClass': !exists(json, 'mainClass') ? undefined : json['mainClass'],
        'mainApplicationFile': !exists(json, 'mainApplicationFile') ? undefined : json['mainApplicationFile'],
        'arguments': !exists(json, 'arguments') ? undefined : json['arguments'],
        'hadoopConf': !exists(json, 'hadoopConf') ? undefined : json['hadoopConf'],
        'sparkConf': !exists(json, 'sparkConf') ? undefined : json['sparkConf'],
        'sparkConfigMap': !exists(json, 'sparkConfigMap') ? undefined : json['sparkConfigMap'],
        'hadoopConfigMap': !exists(json, 'hadoopConfigMap') ? undefined : json['hadoopConfigMap'],
        'executor': !exists(json, 'executor') ? undefined : V1SparkReplicaFromJSON(json['executor']),
        'driver': !exists(json, 'driver') ? undefined : V1SparkReplicaFromJSON(json['driver']),
    };
}

export function V1SparkJobToJSON(value?: V1SparkJob | null): any {
    if (value === undefined) {
        return undefined;
    }
    if (value === null) {
        return null;
    }
    return {

        'kind': value.kind,
        'connections': value.connections,
        'volumes': value.volumes,
        'type': V1SparkJobTypeToJSON(value.type),
        'sparkVersion': value.sparkVersion,
        'pythonVersion': value.pythonVersion,
        'deployMode': SparkJobDeployModeToJSON(value.deployMode),
        'mainClass': value.mainClass,
        'mainApplicationFile': value.mainApplicationFile,
        'arguments': value.arguments,
        'hadoopConf': value.hadoopConf,
        'sparkConf': value.sparkConf,
        'sparkConfigMap': value.sparkConfigMap,
        'hadoopConfigMap': value.hadoopConfigMap,
        'executor': V1SparkReplicaToJSON(value.executor),
        'driver': V1SparkReplicaToJSON(value.driver),
    };
}

